$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json
name: blue
endpoint_name: tobi-care-ms-promptflow-prod
# model: azureml:tobi-llm-chat-model:1
  # You can also specify model files path inline
model:
  path: ../code
  properties:
    # endpoint detail UI Test tab needs this property to know it's from prompt flow
    azureml.promptflow.source_flow_id: chat-with-web-model
    
    # Following are properties only for chat flow 
    # endpoint detail UI Test tab needs this property to know it's a chat flow
    azureml.promptflow.mode: chat
    # endpoint detail UI Test tab needs this property to know which is the input column for chat flow
    azureml.promptflow.chat_input: question
    # endpoint detail UI Test tab needs this property to know which is the output column for chat flow
    azureml.promptflow.chat_output: answer
environment: 
  image: mcr.microsoft.com/azureml/promptflow/promptflow-runtime:latest
  # inference config is used to build a serving container for online deployments
  inference_config:
    liveness_route:
      path: /health
      port: 8080
    readiness_route:
      path: /health
      port: 8080
    scoring_route:
      path: /score
      port: 8080
instance_type: Standard_DS3_v2
instance_count: 1
request_settings:
    request_timeout_ms: 90000
environment_variables:
  # "compute" mode is the default mode, if you want to deploy to serving mode, you need to set this env variable to "serving"
  PROMPTFLOW_RUN_MODE: serving

  # for pulling connections from workspace
  PRT_CONFIG_OVERRIDE: deployment.subscription_id=<sub-id>,deployment.resource_group=<resource-group>,deployment.workspace_name=<workspace-name>,deployment.endpoint_name=<endpoint-name>,deployment.deployment_name=<endpoint-deployment-name>

  # (Optional) When there are multiple fields in the response, using this env variable will filter the fields to expose in the response.
  # For example, if there are 2 flow outputs: "answer", "context", and I only want to have "answer" in the endpoint response, I can set this env variable to '["answer"]'.
  # If you don't set this environment, by default all flow outputs will be included in the endpoint response.
  PROMPTFLOW_RESPONSE_INCLUDED_FIELDS: '["answer"]'